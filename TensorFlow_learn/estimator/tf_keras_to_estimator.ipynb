{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "sys.version_info(major=3, minor=6, micro=4, releaselevel='final', serial=0)\n",
      "matplotlib 2.2.3\n",
      "numpy 1.18.1\n",
      "pandas 0.22.0\n",
      "sklearn 0.19.1\n",
      "tensorflow 2.1.0\n",
      "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "# https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
    "# https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
    "\n",
    "# 定义训练集和测试机的文件名路径\n",
    "train_file = './data/titanic/train.csv'\n",
    "eval_file = './data/titanic/eval.csv'\n",
    "\n",
    "# 用 pandas 把两个数据集读取进来\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# survived 是我们要预测的值, 所以先从特征值里面删除\n",
    "y_train = train_df.pop('survived')\n",
    "y_eval = eval_df.pop('survived')\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())\n",
    "print(y_train.head())\n",
    "print(y_eval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe() 数据集中的统计量\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 9) (264, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, eval_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13a11f9e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 泰坦尼克号上的乘客年龄分布, bins=分成多少份\n",
    "train_df.age.hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13a2e2470>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 不同性别的人各有多少\n",
    "train_df.sex.value_counts().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13c386ef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 不同仓位的乘客各有多少\n",
    "train_df['class'].value_counts().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13c4fb6d8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 获救人群性别占比\n",
    "pd.concat([train_df, y_train], axis = 1).groupby('sex').survived.mean().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "# 最简单的机器学习输入数据是把预测值去掉，把数据用矩阵形式输入\n",
    "# 这里用 feature_column 来对数据列做预处理\n",
    "\n",
    "# 定义离散特征\n",
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
    "                      'deck', 'embark_town', 'alone']\n",
    "# 定义连续特征\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "# 特征预处理,定义在 feature_column 集合里\n",
    "feature_columns = []\n",
    "# 对每一个离散特征做处理\n",
    "for categorical_column in categorical_columns:\n",
    "    # 获得离散特征所在列的所有可能的值\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    # onehot 编码\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                categorical_column, vocab)))\n",
    "\n",
    "# 对每一个连续特征做处理\n",
    "for numeric_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            numeric_column, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数构建 Dataset\n",
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True, batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 0      22.0\n",
       " 1      38.0\n",
       " 2      26.0\n",
       " 3      35.0\n",
       " 4      28.0\n",
       " 5       2.0\n",
       " 6      27.0\n",
       " 7      14.0\n",
       " 8       4.0\n",
       " 9      20.0\n",
       " 10     39.0\n",
       " 11     14.0\n",
       " 12      2.0\n",
       " 13     28.0\n",
       " 14     31.0\n",
       " 15     28.0\n",
       " 16     35.0\n",
       " 17     28.0\n",
       " 18     38.0\n",
       " 19     28.0\n",
       " 20     19.0\n",
       " 21     28.0\n",
       " 22     28.0\n",
       " 23     40.0\n",
       " 24     28.0\n",
       " 25     28.0\n",
       " 26     66.0\n",
       " 27     28.0\n",
       " 28     42.0\n",
       " 29     28.0\n",
       "        ... \n",
       " 597    35.0\n",
       " 598    28.0\n",
       " 599    28.0\n",
       " 600     4.0\n",
       " 601    16.0\n",
       " 602    18.0\n",
       " 603    45.0\n",
       " 604    51.0\n",
       " 605    24.0\n",
       " 606    41.0\n",
       " 607    24.0\n",
       " 608    42.0\n",
       " 609    27.0\n",
       " 610    31.0\n",
       " 611     4.0\n",
       " 612    26.0\n",
       " 613    47.0\n",
       " 614    33.0\n",
       " 615    47.0\n",
       " 616    28.0\n",
       " 617    15.0\n",
       " 618    20.0\n",
       " 619    19.0\n",
       " 620    28.0\n",
       " 621    22.0\n",
       " 622    28.0\n",
       " 623    25.0\n",
       " 624    19.0\n",
       " 625    28.0\n",
       " 626    32.0\n",
       " Name: age, Length: 627, dtype: float64, 'alone': 0      n\n",
       " 1      n\n",
       " 2      y\n",
       " 3      n\n",
       " 4      y\n",
       " 5      n\n",
       " 6      n\n",
       " 7      n\n",
       " 8      n\n",
       " 9      y\n",
       " 10     n\n",
       " 11     y\n",
       " 12     n\n",
       " 13     y\n",
       " 14     n\n",
       " 15     y\n",
       " 16     y\n",
       " 17     y\n",
       " 18     n\n",
       " 19     y\n",
       " 20     n\n",
       " 21     y\n",
       " 22     y\n",
       " 23     y\n",
       " 24     n\n",
       " 25     y\n",
       " 26     y\n",
       " 27     n\n",
       " 28     n\n",
       " 29     y\n",
       "       ..\n",
       " 597    y\n",
       " 598    n\n",
       " 599    n\n",
       " 600    n\n",
       " 601    n\n",
       " 602    n\n",
       " 603    n\n",
       " 604    y\n",
       " 605    n\n",
       " 606    n\n",
       " 607    y\n",
       " 608    y\n",
       " 609    n\n",
       " 610    y\n",
       " 611    n\n",
       " 612    y\n",
       " 613    n\n",
       " 614    y\n",
       " 615    y\n",
       " 616    n\n",
       " 617    y\n",
       " 618    y\n",
       " 619    y\n",
       " 620    y\n",
       " 621    y\n",
       " 622    y\n",
       " 623    y\n",
       " 624    y\n",
       " 625    n\n",
       " 626    y\n",
       " Name: alone, Length: 627, dtype: object, 'class': 0       Third\n",
       " 1       First\n",
       " 2       Third\n",
       " 3       First\n",
       " 4       Third\n",
       " 5       Third\n",
       " 6       Third\n",
       " 7      Second\n",
       " 8       Third\n",
       " 9       Third\n",
       " 10      Third\n",
       " 11      Third\n",
       " 12      Third\n",
       " 13     Second\n",
       " 14      Third\n",
       " 15      Third\n",
       " 16     Second\n",
       " 17      First\n",
       " 18      Third\n",
       " 19      Third\n",
       " 20      First\n",
       " 21      Third\n",
       " 22      Third\n",
       " 23      First\n",
       " 24      First\n",
       " 25      Third\n",
       " 26     Second\n",
       " 27      First\n",
       " 28      First\n",
       " 29      Third\n",
       "         ...  \n",
       " 597     Third\n",
       " 598    Second\n",
       " 599     First\n",
       " 600     Third\n",
       " 601     First\n",
       " 602     Third\n",
       " 603     First\n",
       " 604     First\n",
       " 605     Third\n",
       " 606     Third\n",
       " 607    Second\n",
       " 608    Second\n",
       " 609    Second\n",
       " 610     First\n",
       " 611     Third\n",
       " 612     Third\n",
       " 613     First\n",
       " 614     First\n",
       " 615     Third\n",
       " 616    Second\n",
       " 617     Third\n",
       " 618     Third\n",
       " 619     Third\n",
       " 620     Third\n",
       " 621     Third\n",
       " 622    Second\n",
       " 623     Third\n",
       " 624     First\n",
       " 625     Third\n",
       " 626     Third\n",
       " Name: class, Length: 627, dtype: object, 'deck': 0      unknown\n",
       " 1            C\n",
       " 2      unknown\n",
       " 3            C\n",
       " 4      unknown\n",
       " 5      unknown\n",
       " 6      unknown\n",
       " 7      unknown\n",
       " 8            G\n",
       " 9      unknown\n",
       " 10     unknown\n",
       " 11     unknown\n",
       " 12     unknown\n",
       " 13     unknown\n",
       " 14     unknown\n",
       " 15     unknown\n",
       " 16     unknown\n",
       " 17           A\n",
       " 18     unknown\n",
       " 19     unknown\n",
       " 20           C\n",
       " 21     unknown\n",
       " 22     unknown\n",
       " 23     unknown\n",
       " 24           B\n",
       " 25     unknown\n",
       " 26     unknown\n",
       " 27     unknown\n",
       " 28     unknown\n",
       " 29     unknown\n",
       "         ...   \n",
       " 597    unknown\n",
       " 598    unknown\n",
       " 599          C\n",
       " 600    unknown\n",
       " 601          D\n",
       " 602    unknown\n",
       " 603    unknown\n",
       " 604          E\n",
       " 605    unknown\n",
       " 606    unknown\n",
       " 607    unknown\n",
       " 608    unknown\n",
       " 609    unknown\n",
       " 610          A\n",
       " 611    unknown\n",
       " 612    unknown\n",
       " 613          D\n",
       " 614          B\n",
       " 615    unknown\n",
       " 616    unknown\n",
       " 617    unknown\n",
       " 618    unknown\n",
       " 619    unknown\n",
       " 620    unknown\n",
       " 621    unknown\n",
       " 622    unknown\n",
       " 623    unknown\n",
       " 624          B\n",
       " 625    unknown\n",
       " 626    unknown\n",
       " Name: deck, Length: 627, dtype: object, 'embark_town': 0      Southampton\n",
       " 1        Cherbourg\n",
       " 2      Southampton\n",
       " 3      Southampton\n",
       " 4       Queenstown\n",
       " 5      Southampton\n",
       " 6      Southampton\n",
       " 7        Cherbourg\n",
       " 8      Southampton\n",
       " 9      Southampton\n",
       " 10     Southampton\n",
       " 11     Southampton\n",
       " 12      Queenstown\n",
       " 13     Southampton\n",
       " 14     Southampton\n",
       " 15       Cherbourg\n",
       " 16     Southampton\n",
       " 17     Southampton\n",
       " 18     Southampton\n",
       " 19       Cherbourg\n",
       " 20     Southampton\n",
       " 21      Queenstown\n",
       " 22     Southampton\n",
       " 23       Cherbourg\n",
       " 24       Cherbourg\n",
       " 25      Queenstown\n",
       " 26     Southampton\n",
       " 27       Cherbourg\n",
       " 28     Southampton\n",
       " 29       Cherbourg\n",
       "           ...     \n",
       " 597      Cherbourg\n",
       " 598    Southampton\n",
       " 599      Cherbourg\n",
       " 600    Southampton\n",
       " 601    Southampton\n",
       " 602    Southampton\n",
       " 603    Southampton\n",
       " 604    Southampton\n",
       " 605      Cherbourg\n",
       " 606    Southampton\n",
       " 607    Southampton\n",
       " 608    Southampton\n",
       " 609      Cherbourg\n",
       " 610    Southampton\n",
       " 611    Southampton\n",
       " 612    Southampton\n",
       " 613    Southampton\n",
       " 614    Southampton\n",
       " 615    Southampton\n",
       " 616      Cherbourg\n",
       " 617      Cherbourg\n",
       " 618    Southampton\n",
       " 619    Southampton\n",
       " 620    Southampton\n",
       " 621    Southampton\n",
       " 622    Southampton\n",
       " 623    Southampton\n",
       " 624    Southampton\n",
       " 625    Southampton\n",
       " 626     Queenstown\n",
       " Name: embark_town, Length: 627, dtype: object, 'fare': 0        7.2500\n",
       " 1       71.2833\n",
       " 2        7.9250\n",
       " 3       53.1000\n",
       " 4        8.4583\n",
       " 5       21.0750\n",
       " 6       11.1333\n",
       " 7       30.0708\n",
       " 8       16.7000\n",
       " 9        8.0500\n",
       " 10      31.2750\n",
       " 11       7.8542\n",
       " 12      29.1250\n",
       " 13      13.0000\n",
       " 14      18.0000\n",
       " 15       7.2250\n",
       " 16      26.0000\n",
       " 17      35.5000\n",
       " 18      31.3875\n",
       " 19       7.2250\n",
       " 20     263.0000\n",
       " 21       7.8792\n",
       " 22       7.8958\n",
       " 23      27.7208\n",
       " 24     146.5208\n",
       " 25       7.7500\n",
       " 26      10.5000\n",
       " 27      82.1708\n",
       " 28      52.0000\n",
       " 29       7.2292\n",
       "          ...   \n",
       " 597      7.8958\n",
       " 598     33.0000\n",
       " 599     89.1042\n",
       " 600     31.2750\n",
       " 601     39.4000\n",
       " 602      9.3500\n",
       " 603    164.8667\n",
       " 604     26.5500\n",
       " 605     19.2583\n",
       " 606     14.1083\n",
       " 607     13.0000\n",
       " 608     13.0000\n",
       " 609     13.8583\n",
       " 610     50.4958\n",
       " 611     11.1333\n",
       " 612      7.8958\n",
       " 613     52.5542\n",
       " 614      5.0000\n",
       " 615      9.0000\n",
       " 616     24.0000\n",
       " 617      7.2250\n",
       " 618      9.8458\n",
       " 619      7.8958\n",
       " 620      7.8958\n",
       " 621     10.5167\n",
       " 622     10.5000\n",
       " 623      7.0500\n",
       " 624     30.0000\n",
       " 625     23.4500\n",
       " 626      7.7500\n",
       " Name: fare, Length: 627, dtype: float64, 'n_siblings_spouses': 0      1\n",
       " 1      1\n",
       " 2      0\n",
       " 3      1\n",
       " 4      0\n",
       " 5      3\n",
       " 6      0\n",
       " 7      1\n",
       " 8      1\n",
       " 9      0\n",
       " 10     1\n",
       " 11     0\n",
       " 12     4\n",
       " 13     0\n",
       " 14     1\n",
       " 15     0\n",
       " 16     0\n",
       " 17     0\n",
       " 18     1\n",
       " 19     0\n",
       " 20     3\n",
       " 21     0\n",
       " 22     0\n",
       " 23     0\n",
       " 24     1\n",
       " 25     0\n",
       " 26     0\n",
       " 27     1\n",
       " 28     1\n",
       " 29     0\n",
       "       ..\n",
       " 597    0\n",
       " 598    0\n",
       " 599    1\n",
       " 600    4\n",
       " 601    0\n",
       " 602    0\n",
       " 603    1\n",
       " 604    0\n",
       " 605    0\n",
       " 606    2\n",
       " 607    0\n",
       " 608    0\n",
       " 609    1\n",
       " 610    0\n",
       " 611    1\n",
       " 612    0\n",
       " 613    1\n",
       " 614    0\n",
       " 615    0\n",
       " 616    1\n",
       " 617    0\n",
       " 618    0\n",
       " 619    0\n",
       " 620    0\n",
       " 621    0\n",
       " 622    0\n",
       " 623    0\n",
       " 624    0\n",
       " 625    1\n",
       " 626    0\n",
       " Name: n_siblings_spouses, Length: 627, dtype: int64, 'parch': 0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       " 5      1\n",
       " 6      2\n",
       " 7      0\n",
       " 8      1\n",
       " 9      0\n",
       " 10     5\n",
       " 11     0\n",
       " 12     1\n",
       " 13     0\n",
       " 14     0\n",
       " 15     0\n",
       " 16     0\n",
       " 17     0\n",
       " 18     5\n",
       " 19     0\n",
       " 20     2\n",
       " 21     0\n",
       " 22     0\n",
       " 23     0\n",
       " 24     0\n",
       " 25     0\n",
       " 26     0\n",
       " 27     0\n",
       " 28     0\n",
       " 29     0\n",
       "       ..\n",
       " 597    0\n",
       " 598    1\n",
       " 599    0\n",
       " 600    2\n",
       " 601    1\n",
       " 602    1\n",
       " 603    1\n",
       " 604    0\n",
       " 605    3\n",
       " 606    0\n",
       " 607    0\n",
       " 608    0\n",
       " 609    0\n",
       " 610    0\n",
       " 611    1\n",
       " 612    0\n",
       " 613    1\n",
       " 614    0\n",
       " 615    0\n",
       " 616    0\n",
       " 617    0\n",
       " 618    0\n",
       " 619    0\n",
       " 620    0\n",
       " 621    0\n",
       " 622    0\n",
       " 623    0\n",
       " 624    0\n",
       " 625    2\n",
       " 626    0\n",
       " Name: parch, Length: 627, dtype: int64, 'sex': 0        male\n",
       " 1      female\n",
       " 2      female\n",
       " 3      female\n",
       " 4        male\n",
       " 5        male\n",
       " 6      female\n",
       " 7      female\n",
       " 8      female\n",
       " 9        male\n",
       " 10       male\n",
       " 11     female\n",
       " 12       male\n",
       " 13       male\n",
       " 14     female\n",
       " 15     female\n",
       " 16       male\n",
       " 17       male\n",
       " 18     female\n",
       " 19       male\n",
       " 20       male\n",
       " 21     female\n",
       " 22       male\n",
       " 23       male\n",
       " 24     female\n",
       " 25     female\n",
       " 26       male\n",
       " 27       male\n",
       " 28       male\n",
       " 29       male\n",
       "         ...  \n",
       " 597      male\n",
       " 598      male\n",
       " 599    female\n",
       " 600      male\n",
       " 601    female\n",
       " 602    female\n",
       " 603    female\n",
       " 604      male\n",
       " 605    female\n",
       " 606      male\n",
       " 607      male\n",
       " 608    female\n",
       " 609    female\n",
       " 610      male\n",
       " 611      male\n",
       " 612      male\n",
       " 613    female\n",
       " 614      male\n",
       " 615      male\n",
       " 616    female\n",
       " 617    female\n",
       " 618      male\n",
       " 619      male\n",
       " 620      male\n",
       " 621    female\n",
       " 622      male\n",
       " 623      male\n",
       " 624    female\n",
       " 625    female\n",
       " 626      male\n",
       " Name: sex, Length: 627, dtype: object}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_df 是 pandas.DataFrame 结构, 查看一下将它变成字典的结构\n",
    "dict(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建训练集的 dataset\n",
    "train_dataset = make_dataset(train_df, y_train, batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'female', b'female', b'male', b'male', b'male'], dtype=object)>, 'age': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([28., 28., 49., 28., 28.])>, 'n_siblings_spouses': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 1, 0, 0], dtype=int32)>, 'parch': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 0, 1, 0, 0], dtype=int32)>, 'fare': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([  7.75  , 146.5208, 110.8833,   9.5   ,   0.    ])>, 'class': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'Third', b'First', b'First', b'Third', b'Second'], dtype=object)>, 'deck': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'unknown', b'B', b'C', b'unknown', b'unknown'], dtype=object)>, 'embark_town': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
      "array([b'Queenstown', b'Cherbourg', b'Cherbourg', b'Southampton',\n",
      "       b'Southampton'], dtype=object)>, 'alone': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'y', b'n', b'n', b'y', b'y'], dtype=object)>} tf.Tensor([1 1 0 0 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 打印 train_dataset 的值\n",
    "for x, y in train_dataset.take(1):\n",
    "    print(x, y)\n",
    "    # 发现 x 是一个字典, y 是一个列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[38.]\n",
      " [28.]\n",
      " [18.]\n",
      " [ 1.]\n",
      " [30.]]\n",
      "WARNING:tensorflow:Layer dense_features_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /Users/S-MINGHAO/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /Users/S-MINGHAO/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 构建好 Dataset 后, 需要把 feature_columns 和 dataset 结合使用 -> keras.layers.DenseFeatures 把 feature_columns 应用到 dataset 里\n",
    "for x, y in train_dataset.take(1):\n",
    "    age_column = feature_columns[7]\n",
    "    gender_column = feature_columns[0]\n",
    "    print(keras.layers.DenseFeatures(age_column)(x).numpy())\n",
    "    print(keras.layers.DenseFeatures(gender_column)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[43.      1.      0.      0.      0.      1.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "  26.25    1.      0.      0.      0.      0.      0.      0.      0.\n",
      "   1.      0.      0.      0.      0.      1.      0.    ]\n",
      " [18.      0.      1.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "   9.8417  0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      0.      1.    ]\n",
      " [28.      1.      0.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      0.      0.      1.      0.\n",
      "   7.75    1.      0.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [36.      0.      1.      0.      0.      1.      0.      0.      0.\n",
      "   0.      0.      1.      0.      0.      0.      1.      0.      0.\n",
      "  12.875   0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [35.      0.      1.      0.      0.      1.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "  26.      0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# 构建好 Dataset 后, 需要把 feature_columns 和 dataset 结合使用 -> keras.layers.DenseFeatures 把 feature_columns 应用到 dataset 里\n",
    "for x, y in train_dataset.take(1):\n",
    "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax'),\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer = keras.optimizers.SGD(lr=0.01),\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 20 steps, validate for 8 steps\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 2.2299 - accuracy: 0.5813 - val_loss: 0.9216 - val_accuracy: 0.6758\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.6719 - val_loss: 0.6453 - val_accuracy: 0.6758\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.6656 - val_loss: 0.6813 - val_accuracy: 0.6328\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.6406 - val_loss: 0.6017 - val_accuracy: 0.6953\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6719 - val_loss: 0.6395 - val_accuracy: 0.6797\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.6938 - val_loss: 0.6148 - val_accuracy: 0.6680\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.7125 - val_loss: 0.6009 - val_accuracy: 0.6992\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.6891 - val_loss: 0.5972 - val_accuracy: 0.6719\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.7031 - val_loss: 0.6319 - val_accuracy: 0.6328\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7047 - val_loss: 0.6170 - val_accuracy: 0.6875\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.6953 - val_loss: 0.5874 - val_accuracy: 0.7148\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.7031 - val_loss: 0.6073 - val_accuracy: 0.7031\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7078 - val_loss: 0.6029 - val_accuracy: 0.6992\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.6875 - val_loss: 0.5898 - val_accuracy: 0.7344\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7266 - val_loss: 0.5747 - val_accuracy: 0.7070\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6070 - accuracy: 0.6891 - val_loss: 0.6179 - val_accuracy: 0.6680\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.6953 - val_loss: 0.5740 - val_accuracy: 0.7148\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7172 - val_loss: 0.5559 - val_accuracy: 0.7031\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.6875 - val_loss: 0.5802 - val_accuracy: 0.7148\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.7063 - val_loss: 0.6414 - val_accuracy: 0.7070\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7344 - val_loss: 0.5660 - val_accuracy: 0.6992\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.6797 - val_loss: 0.5988 - val_accuracy: 0.6523\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7031 - val_loss: 0.5576 - val_accuracy: 0.7148\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7453 - val_loss: 0.5515 - val_accuracy: 0.7031\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7203 - val_loss: 0.5551 - val_accuracy: 0.7031\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7234 - val_loss: 0.5449 - val_accuracy: 0.7109\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7312 - val_loss: 0.5690 - val_accuracy: 0.7109\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.7000 - val_loss: 0.5859 - val_accuracy: 0.6953\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7234 - val_loss: 0.5678 - val_accuracy: 0.6523\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.7188 - val_loss: 0.5463 - val_accuracy: 0.7109\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7516 - val_loss: 0.6022 - val_accuracy: 0.6992\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7437 - val_loss: 0.5522 - val_accuracy: 0.7109\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7219 - val_loss: 0.6578 - val_accuracy: 0.6836\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7125 - val_loss: 0.5405 - val_accuracy: 0.6875\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7219 - val_loss: 0.5604 - val_accuracy: 0.7383\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7453 - val_loss: 0.5536 - val_accuracy: 0.6875\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7344 - val_loss: 0.5345 - val_accuracy: 0.7266\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7453 - val_loss: 0.5363 - val_accuracy: 0.7109\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7297 - val_loss: 0.5256 - val_accuracy: 0.7344\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.6922 - val_loss: 0.5995 - val_accuracy: 0.6797\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7234 - val_loss: 0.5755 - val_accuracy: 0.6992\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7500 - val_loss: 0.5945 - val_accuracy: 0.7188\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7281 - val_loss: 0.5468 - val_accuracy: 0.6953\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7500 - val_loss: 0.5414 - val_accuracy: 0.6953\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7375 - val_loss: 0.5236 - val_accuracy: 0.7227\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.7266 - val_loss: 0.5181 - val_accuracy: 0.7461\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7594 - val_loss: 0.5317 - val_accuracy: 0.7188\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7344 - val_loss: 0.5269 - val_accuracy: 0.7578\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7328 - val_loss: 0.5152 - val_accuracy: 0.7383\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7297 - val_loss: 0.5296 - val_accuracy: 0.7266\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7656 - val_loss: 0.6209 - val_accuracy: 0.6992\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7453 - val_loss: 0.5320 - val_accuracy: 0.7266\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7437 - val_loss: 0.5254 - val_accuracy: 0.7266\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5461 - accuracy: 0.7312 - val_loss: 0.5505 - val_accuracy: 0.7344\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7547 - val_loss: 0.5372 - val_accuracy: 0.7305\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7344 - val_loss: 0.5446 - val_accuracy: 0.6758\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7281 - val_loss: 0.5126 - val_accuracy: 0.7461\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7594 - val_loss: 0.5177 - val_accuracy: 0.7461\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7266 - val_loss: 0.5424 - val_accuracy: 0.7383\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7594 - val_loss: 0.5767 - val_accuracy: 0.6992\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7547 - val_loss: 0.5131 - val_accuracy: 0.7422\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7516 - val_loss: 0.5497 - val_accuracy: 0.7266\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.7203 - val_loss: 0.5166 - val_accuracy: 0.7422\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7547 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7297 - val_loss: 0.5194 - val_accuracy: 0.7461\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7578 - val_loss: 0.5160 - val_accuracy: 0.7461\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.7609 - val_loss: 0.5214 - val_accuracy: 0.7383\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7594 - val_loss: 0.5622 - val_accuracy: 0.6953\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7594 - val_loss: 0.5552 - val_accuracy: 0.7031\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.7406 - val_loss: 0.5204 - val_accuracy: 0.7227\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7531 - val_loss: 0.5781 - val_accuracy: 0.7109\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7625 - val_loss: 0.5361 - val_accuracy: 0.7266\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7609 - val_loss: 0.5093 - val_accuracy: 0.7461\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7797 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7609 - val_loss: 0.5052 - val_accuracy: 0.7461\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7469 - val_loss: 0.5209 - val_accuracy: 0.7305\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7953 - val_loss: 0.5013 - val_accuracy: 0.7617\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7453 - val_loss: 0.5457 - val_accuracy: 0.7148\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7797 - val_loss: 0.5191 - val_accuracy: 0.7266\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7766 - val_loss: 0.4963 - val_accuracy: 0.7695\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7625 - val_loss: 0.4985 - val_accuracy: 0.7617\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7500 - val_loss: 0.5236 - val_accuracy: 0.7266\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5142 - accuracy: 0.7719 - val_loss: 0.5037 - val_accuracy: 0.7305\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7469 - val_loss: 0.5231 - val_accuracy: 0.7344\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7719 - val_loss: 0.5529 - val_accuracy: 0.7266\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7891 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7578 - val_loss: 0.5023 - val_accuracy: 0.7539\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7469 - val_loss: 0.5311 - val_accuracy: 0.7266\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7594 - val_loss: 0.4958 - val_accuracy: 0.7422\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7859 - val_loss: 0.5483 - val_accuracy: 0.7383\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.7812 - val_loss: 0.5065 - val_accuracy: 0.7461\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7797 - val_loss: 0.5222 - val_accuracy: 0.7578\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7594 - val_loss: 0.6026 - val_accuracy: 0.6875\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7391 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.7578 - val_loss: 0.5048 - val_accuracy: 0.7695\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7688 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7672 - val_loss: 0.7260 - val_accuracy: 0.6289\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7597 - val_loss: 0.5436 - val_accuracy: 0.7031\n",
      "Epoch 99/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
      " 0/20 [..............................] - ETA: 0s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Empty training data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d4c15059767c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                    \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                    \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                    epochs = 100)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m   \u001b[0;31m# End of an epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m   \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Empty training data.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Empty training data."
     ]
    }
   ],
   "source": [
    "# 1. model.fit\n",
    "# 2. model -> estimator -> train\n",
    "\n",
    "train_dataset = make_dataset(train_df, y_train, epochs = 100)\n",
    "eval_dataset = make_dataset(eval_df, y_eval, epochs = 1, shuffle = False)\n",
    "history = model.fit(train_dataset,\n",
    "                   validation_data = eval_dataset,\n",
    "                   steps_per_epoch = 20,\n",
    "                   validation_steps = 8,\n",
    "                   epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/7l/7__2pj9n7b36yhpdfxwkr3rr0000gn/T/tmp3lk7r54n\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
      "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/7l/7__2pj9n7b36yhpdfxwkr3rr0000gn/T/tmp3lk7r54n', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /Users/S-MINGHAO/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/S-MINGHAO/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2f8b5031292a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 1. function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 2. returun a. (features, labels) b. dataset -> (feature, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1162\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1192\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1194\u001b[0;31m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1195\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[0;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[0min_place_reset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0moptimizer_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m       optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msample_weight_tensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36mclone_and_build_model\u001b[0;34m(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\u001b[0m\n\u001b[1;32m    636\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m       \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m       if all([\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    419\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     return _clone_sequential_model(\n\u001b[0;32m--> 421\u001b[0;31m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[1;32m    422\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     return _clone_functional_model(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    338\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0morigin_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    985\u001b[0m                         sparse_tensor.SparseTensor)):\n\u001b[1;32m    986\u001b[0m     raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) +\n\u001b[0;32m--> 987\u001b[0;31m                      '`. Expected a symbolic tensor instance.')\n\u001b[0m\u001b[1;32m    988\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance."
     ]
    }
   ],
   "source": [
    "estimator = keras.estimator.model_to_estimator(model)\n",
    "# 1. function\n",
    "# 2. returun a. (features, labels) b. dataset -> (feature, label)\n",
    "estimator.train(input_fn = lambda: make_dataset(train_df, y_train, epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
