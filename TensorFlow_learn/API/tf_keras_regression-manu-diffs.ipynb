{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California housing dataset.\n",
      "\n",
      "The original database is available from StatLib\n",
      "\n",
      "    http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The data contains 20,640 observations on 9 variables.\n",
      "\n",
      "This dataset contains the average house value as target variable\n",
      "and the following input variables (features): average income,\n",
      "housing average age, average rooms, average bedrooms, population,\n",
      "average occupation, latitude, and longitude in that order.\n",
      "\n",
      "References\n",
      "----------\n",
      "\n",
      "Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "Statistics and Probability Letters, 33 (1997) 291-297.\n",
      "\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(housing.data, housing.target, random_state=7)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_all, y_train_all, random_state=11)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.fit_transform(x_valid)\n",
    "x_test_scaled = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# metric使用\n",
    "\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "print(metric([5.], [2.]))\n",
    "print(metric([0.], [1.]))\n",
    "print(metric.result())\n",
    "\n",
    "metric.reset_states()\n",
    "metric([1.], [3.])\n",
    "print(metric.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0 train mse: 6.95589645\t valid mse:  3.4704240893742857\n",
      "Epoch 1 train mse: 1.2740322\t valid mse:  3.0373539784600445\n",
      "Epoch 2 train mse: 1.2465087\t valid mse:  3.2072144491629064\n",
      "Epoch 3 train mse: 1.2500273\t valid mse:  3.1225950495765415\n",
      "Epoch 4 train mse: 1.2563758\t valid mse:  2.9680842912017895\n",
      "Epoch 5 train mse: 1.2910694\t valid mse:  2.930150066006837\n",
      "Epoch 6 train mse: 1.2529843\t valid mse:  2.9335899050954373\n",
      "Epoch 7 train mse: 1.2751586\t valid mse:  2.914765168390398\n",
      "Epoch 8 train mse: 1.2526675\t valid mse:  2.8409621798188973\n",
      "Epoch 9 train mse: 1.2346314\t valid mse:  2.8473538534406213\n",
      "Epoch 10 train mse: 1.2686089\t valid mse:  2.8357249297178937\n",
      "Epoch 11 train mse: 1.2621248\t valid mse:  2.7825520577888523\n",
      "Epoch 12 train mse: 1.2824231\t valid mse:  2.803348347349731\n",
      "Epoch 13 train mse: 1.23271327\t valid mse:  2.799629185161779\n",
      "Epoch 14 train mse: 1.2828034\t valid mse:  2.8131376290186894\n",
      "Epoch 15 train mse: 1.26163926\t valid mse:  2.844196454835401\n",
      "Epoch 16 train mse: 1.2730997\t valid mse:  2.7831757039579648\n",
      "Epoch 17 train mse: 1.249179\t valid mse:  2.806460238021502\n",
      "Epoch 18 train mse: 1.2485268\t valid mse:  2.77342422900525\n",
      "Epoch 19 train mse: 1.2449732\t valid mse:  2.7827834364793667\n",
      "Epoch 20 train mse: 1.2784172\t valid mse:  2.821408908543813\n",
      "Epoch 21 train mse: 1.2616992\t valid mse:  2.789715209590622\n",
      "Epoch 22 train mse: 1.3023251\t valid mse:  2.785554523618858\n",
      "Epoch 23 train mse: 1.2734331\t valid mse:  2.791081037382339\n",
      "Epoch 24 train mse: 1.2734144\t valid mse:  2.776053491528865\n",
      "Epoch 25 train mse: 1.2512444\t valid mse:  2.7726389181530173\n",
      "Epoch 26 train mse: 1.2484423\t valid mse:  2.789805911128075\n",
      "Epoch 27 train mse: 1.2667229\t valid mse:  2.7718984427286673\n",
      "Epoch 28 train mse: 1.2722569\t valid mse:  2.7804801153202106\n",
      "Epoch 29 train mse: 1.2830518\t valid mse:  2.7831429403882013\n",
      "Epoch 30 train mse: 1.2744168\t valid mse:  2.8123657854880304\n",
      "Epoch 31 train mse: 1.2616608\t valid mse:  2.779159029503247\n",
      "Epoch 32 train mse: 1.2766675\t valid mse:  2.791953288800094\n",
      "Epoch 33 train mse: 1.2741969\t valid mse:  2.7564963190822014\n",
      "Epoch 34 train mse: 1.2561347\t valid mse:  2.7798062636471075\n",
      "Epoch 35 train mse: 1.2587886\t valid mse:  2.7927840218864692\n",
      "Epoch 36 train mse: 1.2554538\t valid mse:  2.791810102261635\n",
      "Epoch 37 train mse: 1.2449539\t valid mse:  2.755653938326196\n",
      "Epoch 38 train mse: 1.2503815\t valid mse:  2.748964769232955\n",
      "Epoch 39 train mse: 1.2780691\t valid mse:  2.770129691852033\n",
      "Epoch 40 train mse: 1.255953\t valid mse:  2.7745306176382893\n",
      "Epoch 41 train mse: 1.2554584\t valid mse:  2.7662491857185287\n",
      "Epoch 42 train mse: 1.2805123\t valid mse:  2.779243634842742\n",
      "Epoch 43 train mse: 1.2658076\t valid mse:  2.7492354539212998\n",
      "Epoch 44 train mse: 1.2654536\t valid mse:  2.758206527402143\n",
      "Epoch 45 train mse: 1.2549047\t valid mse:  2.755984774658745\n",
      "Epoch 46 train mse: 1.2763771\t valid mse:  2.77560237909728\n",
      "Epoch 47 train mse: 1.2893692\t valid mse:  2.7541280768112775\n",
      "Epoch 48 train mse: 1.273849\t valid mse:  2.75561736626287\n",
      "Epoch 49 train mse: 1.2433813\t valid mse:  2.749683526163512\n",
      "Epoch 50 train mse: 1.2656851\t valid mse:  2.767272728367846\n",
      "Epoch 51 train mse: 1.2825531\t valid mse:  2.7615928157184224\n",
      "Epoch 52 train mse: 1.2535484\t valid mse:  2.772127573697462\n",
      "Epoch 53 train mse: 1.2501554\t valid mse:  2.775414787426039\n",
      "Epoch 54 train mse: 1.2618053\t valid mse:  2.790058145670756\n",
      "Epoch 55 train mse: 1.2704678\t valid mse:  2.7580945076410748\n",
      "Epoch 56 train mse: 1.258358\t valid mse:  2.7587306612478395\n",
      "Epoch 57 train mse: 1.2421252\t valid mse:  2.740427477547982\n",
      "Epoch 58 train mse: 1.2518569\t valid mse:  2.7703409673605637\n",
      "Epoch 59 train mse: 1.2316403\t valid mse:  2.7589926170240613\n",
      "Epoch 60 train mse: 1.2513877\t valid mse:  2.7535000518566792\n",
      "Epoch 61 train mse: 1.2688152\t valid mse:  2.761181357217201\n",
      "Epoch 62 train mse: 1.2688555\t valid mse:  2.7548759677229095\n",
      "Epoch 63 train mse: 1.2385367\t valid mse:  2.7546263072964083\n",
      "Epoch 64 train mse: 1.2529436\t valid mse:  2.7596013869705294\n",
      "Epoch 65 train mse: 1.28335565\t valid mse:  2.758845332620349\n",
      "Epoch 66 train mse: 1.2510685\t valid mse:  2.763312090443643\n",
      "Epoch 67 train mse: 1.2771624\t valid mse:  2.7450295788879315\n",
      "Epoch 68 train mse: 1.26197964\t valid mse:  2.7528398244452372\n",
      "Epoch 69 train mse: 1.2503458\t valid mse:  2.762803246131552\n",
      "Epoch 70 train mse: 1.2446499\t valid mse:  2.737412462895818\n",
      "Epoch 71 train mse: 1.2615715\t valid mse:  2.7371836961748652\n",
      "Epoch 72 train mse: 1.2373077\t valid mse:  2.7380152000437046\n",
      "Epoch 73 train mse: 1.2401463\t valid mse:  2.7610863246508432\n",
      "Epoch 74 train mse: 1.2424511\t valid mse:  2.734625542179358\n",
      "Epoch 75 train mse: 1.2752553\t valid mse:  2.7515863171210286\n",
      "Epoch 76 train mse: 1.219653\t valid mse:  2.7384565557311653\n",
      "Epoch 77 train mse: 1.243544\t valid mse:  2.757267765266499\n",
      "Epoch 78 train mse: 1.2754338\t valid mse:  2.738826297007328\n",
      "Epoch 79 train mse: 1.2431227\t valid mse:  2.7526503172612777\n",
      "Epoch 80 train mse: 1.2487695\t valid mse:  2.74711764872005\n",
      "Epoch 81 train mse: 1.2590826\t valid mse:  2.7367290216585296\n",
      "Epoch 82 train mse: 1.2398347\t valid mse:  2.741290930879589\n",
      "Epoch 83 train mse: 1.2379851\t valid mse:  2.7463860235315574\n",
      "Epoch 84 train mse: 1.2578751\t valid mse:  2.7671729589874574\n",
      "Epoch 85 train mse: 1.2581353\t valid mse:  2.748813138250685\n",
      "Epoch 86 train mse: 1.3005799\t valid mse:  2.7358079738239924\n",
      "Epoch 87 train mse: 1.2538347\t valid mse:  2.741089446646358\n",
      "Epoch 88 train mse: 1.2645862\t valid mse:  2.7387120952167754\n",
      "Epoch 89 train mse: 1.2832445\t valid mse:  2.763785930073641\n",
      "Epoch 90 train mse: 1.248625\t valid mse:  2.744767368282887\n",
      "Epoch 91 train mse: 1.2911499\t valid mse:  2.751192722081069\n",
      "Epoch 92 train mse: 1.2608182\t valid mse:  2.7557949303164606\n",
      "Epoch 93 train mse: 1.2756746\t valid mse:  2.752475705886166\n",
      "Epoch 94 train mse: 1.2745683\t valid mse:  2.7381940385809704\n",
      "Epoch 95 train mse: 1.2427527\t valid mse:  2.7388613367998507\n",
      "Epoch 96 train mse: 1.2613978\t valid mse:  2.7634021524564027\n",
      "Epoch 97 train mse: 1.2710514\t valid mse:  2.7462395287313988\n",
      "Epoch 98 train mse: 1.246081\t valid mse:  2.731775116704357\n",
      "Epoch 99 train mse: 1.2457099\t valid mse:  2.733614160107333\n"
     ]
    }
   ],
   "source": [
    "# 1. batch 遍历训练集 metric\n",
    "#    1.1 自动求导\n",
    "# 2. epoch 结束 验证集 metric\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(x_train_scaled) // batch_size\n",
    "optimizer = keras.optimizers.SGD()\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "\n",
    "def random_batch(x, y, batch_size=32):\n",
    "    # 随机取索引\n",
    "    idx = np.random.randint(0, len(x), size=batch_size)\n",
    "    return x[idx], y[idx] # 因为 x, y 都是numpy类型所以可以这样取数据\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    metric.reset_states()\n",
    "    for step in range(steps_per_epoch):\n",
    "        x_batch, y_batch = random_batch(x_train_scaled, y_train, batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch)\n",
    "            loss = tf.reduce_mean(keras.losses.mean_squared_error(y_batch, y_pred))\n",
    "            metric(y_batch, y_pred)\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        grads_and_vars = zip(grads, model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars)\n",
    "        print(\"\\rEpoch\", epoch, \"train mse:\", metric.result().numpy(), end=\"\")\n",
    "    y_valid_pred = model(x_valid_scaled)\n",
    "    valid_loss = tf.reduce_mean(keras.losses.mean_squared_error(y_valid_pred, y_valid))\n",
    "    print(\"\\t\", \"valid mse: \", valid_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
